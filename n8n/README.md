# News AI Agent - MVP Setup Guide

Automatisierter News-Aggregator mit KI-Zusammenfassungen und tÃ¤glichem Email-Digest.

## ğŸ¯ Features

- **RSS Feed Ingestion**: Automatisches Abrufen von News aus mehreren RSS-Feeds (alle 15 Minuten)
- **Deduplizierung**: Intelligente Erkennung und Filterung doppelter Artikel
- **KI-Zusammenfassungen**: Automatische Generierung von Kurz- und Langzusammenfassungen via OpenAI
- **TÃ¤glicher Digest**: SchÃ¶n formatierte HTML-Email mit allen neuen Artikeln (tÃ¤glich um 8:00 Uhr)
- **Persistente Speicherung**: PostgreSQL-Datenbank fÃ¼r Article-Historie

## ğŸ“‹ Voraussetzungen

- Docker & Docker Compose installiert
- OpenAI API Key ([hier erhalten](https://platform.openai.com/api-keys))
- SMTP Email-Account (z.B. Gmail mit App-Passwort)

## ğŸš€ Installation & Setup

### 1. Environment Variables einrichten

Kopiere die `env.example` Datei und benenne sie in `.env` um:

```bash
cp env.example .env
```

Bearbeite die `.env` Datei und fÃ¼ge deine Credentials ein:

```bash
# PostgreSQL (kannst du so lassen fÃ¼r lokales Testing)
POSTGRES_USER=n8n
POSTGRES_PASSWORD=dein_sicheres_passwort
POSTGRES_DB=news_agent

# n8n Web-Interface Zugang
N8N_USER=admin
N8N_PASSWORD=dein_n8n_passwort

# OpenAI API Key (ERFORDERLICH!)
OPENAI_API_KEY=sk-dein-openai-key-hier

# Email SMTP (ERFORDERLICH fÃ¼r Email-Digest)
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=deine-email@gmail.com
SMTP_PASSWORD=dein-app-passwort
SMTP_FROM=News Agent <deine-email@gmail.com>

# EmpfÃ¤nger Email
RECIPIENT_EMAIL=deine-email@gmail.com
```

**Wichtig fÃ¼r Gmail:**
- Aktiviere 2-Faktor-Authentifizierung
- Erstelle ein [App-Passwort](https://myaccount.google.com/apppasswords) (nicht dein normales Passwort!)

### 2. Container starten

```bash
cd n8n
docker-compose up -d
```

Die Container starten jetzt:
- **n8n**: http://localhost:5678
- **PostgreSQL**: localhost:5432

PrÃ¼fe den Status:
```bash
docker-compose ps
```

Logs ansehen:
```bash
docker-compose logs -f n8n
docker-compose logs -f postgres
```

### 3. n8n Dashboard Ã¶ffnen

Ã–ffne deinen Browser und gehe zu: **http://localhost:5678**

Login mit den Credentials aus deiner `.env` Datei:
- Username: `admin` (oder was du gesetzt hast)
- Password: dein `N8N_PASSWORD`

### 4. Credentials einrichten

n8n benÃ¶tigt Credentials fÃ¼r externe Services. Gehe zu **Settings â†’ Credentials** und erstelle:

#### PostgreSQL Credentials
- Name: `PostgreSQL account`
- Host: `postgres`
- Database: `news_agent` (oder dein `POSTGRES_DB`)
- User: `n8n` (oder dein `POSTGRES_USER`)
- Password: dein `POSTGRES_PASSWORD`
- Port: `5432`

#### OpenAI Credentials
- Name: `OpenAI account`
- API Key: dein `OPENAI_API_KEY`

#### SMTP Credentials
- Name: `SMTP account`
- Host: `smtp.gmail.com` (oder dein `SMTP_HOST`)
- Port: `587`
- User: dein `SMTP_USER`
- Password: dein `SMTP_PASSWORD`
- Secure: `false` (fÃ¼r STARTTLS)

### 5. Workflows importieren

Gehe zu **Workflows** und importiere die 3 JSON-Dateien aus dem `workflows/` Ordner:

1. **01-rss-ingestion.json** - RSS Feed Abruf
2. **02-summarization.json** - OpenAI Zusammenfassungen
3. **03-email-digest.json** - Email Versand

**So importierst du:**
1. Klicke auf **"Add workflow"** â†’ **"Import from file"**
2. WÃ¤hle die JSON-Datei aus
3. Klicke **"Save"**
4. PrÃ¼fe, ob alle Nodes korrekt verbunden sind

**Wichtig:** Stelle sicher, dass jede Workflow die richtigen Credentials verwendet (siehe Node-Settings).

## ğŸ§ª Testing

### Test 1: Datenbank-Verbindung prÃ¼fen

```bash
docker exec -it news-agent-postgres psql -U n8n -d news_agent -c "SELECT * FROM articles;"
```

Du solltest mindestens einen Test-Artikel sehen.

### Test 2: RSS Ingestion manuell ausfÃ¼hren

1. Ã–ffne Workflow **"01 - RSS Feed Ingestion"**
2. Klicke auf **"Execute Workflow"** (Play-Button oben rechts)
3. Warte 10-20 Sekunden
4. Du solltest grÃ¼ne Checkmarks sehen und eine Meldung wie "Successfully ingested X new articles"

PrÃ¼fe die Datenbank:
```bash
docker exec -it news-agent-postgres psql -U n8n -d news_agent -c "SELECT title, source, processed FROM articles ORDER BY fetched_at DESC LIMIT 5;"
```

### Test 3: Summarization manuell ausfÃ¼hren

1. Ã–ffne Workflow **"02 - Article Summarization"**
2. Klicke auf **"Execute Workflow"**
3. Warte (kann 20-60 Sekunden dauern, abhÃ¤ngig von der Anzahl der Artikel)
4. PrÃ¼fe Ergebnis: "Processed X articles (Y successful)"

PrÃ¼fe die Summaries in der Datenbank:
```bash
docker exec -it news-agent-postgres psql -U n8n -d news_agent -c "SELECT title, summary_short FROM articles WHERE processed = TRUE LIMIT 3;"
```

### Test 4: Email Digest manuell senden

1. Ã–ffne Workflow **"03 - Daily Email Digest"**
2. Klicke auf **"Execute Workflow"**
3. PrÃ¼fe dein Email-Postfach!
4. Du solltest eine schÃ¶n formatierte HTML-Email erhalten

## ğŸ“Š Workflow-Ãœbersicht

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AUTOMATISCHER ABLAUF                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   â° Alle 15 Minuten
        â”‚
        â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ RSS Ingestion   â”‚  â†’ Holt neue Artikel
   â”‚ (Workflow 01)   â”‚  â†’ PrÃ¼ft Duplikate
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â†’ Speichert in DB
            â”‚
            â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚   PostgreSQL    â”‚  â†’ Artikel unprocessed
   â”‚   (Database)    â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
   â° Alle 5 Minuten â”‚
            â”‚
            â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Summarization   â”‚  â†’ Holt 10 unprocessed
   â”‚ (Workflow 02)   â”‚  â†’ OpenAI erstellt Summaries
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â†’ Markiert als processed
            â”‚
            â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚   PostgreSQL    â”‚  â†’ Artikel processed
   â”‚   (Database)    â”‚     aber unsent
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
   â° TÃ¤glich 8:00   â”‚
            â”‚
            â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Email Digest   â”‚  â†’ Sammelt alle unsent
   â”‚ (Workflow 03)   â”‚  â†’ Generiert HTML
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â†’ Sendet Email
            â”‚           â†’ Markiert als sent
            â–¼
       ğŸ“§ Dein Postfach
```

## ğŸ”§ Konfiguration anpassen

### Weitere RSS Feeds hinzufÃ¼gen

1. Ã–ffne Workflow **"01 - RSS Feed Ingestion"**
2. Klicke auf das **"+"** Icon nach dem Schedule Trigger
3. FÃ¼ge einen neuen **"RSS Feed Read"** Node hinzu
4. Gib die Feed-URL ein
5. Verbinde ihn mit dem **"Merge Feeds"** Node
6. Speichern!

**Beliebte News RSS Feeds:**
- TechCrunch: `https://feeds.feedburner.com/TechCrunch/`
- Hacker News: `https://hnrss.org/frontpage`
- Heise: `https://www.heise.de/rss/heise-atom.xml`
- Tagesschau: `https://www.tagesschau.de/xml/rss2/`
- The Verge: `https://www.theverge.com/rss/index.xml`

### Zeitplan Ã¤ndern

**RSS Ingestion:**
- Standard: Alle 15 Minuten
- Ã„ndern: Ã–ffne Workflow â†’ Schedule Trigger Node â†’ "Rule" anpassen

**Summarization:**
- Standard: Alle 5 Minuten
- Ã„ndern: Ã–ffne Workflow â†’ Schedule Trigger Node â†’ "Rule" anpassen

**Email Digest:**
- Standard: TÃ¤glich um 8:00 Uhr
- Ã„ndern: Ã–ffne Workflow â†’ Schedule Trigger Node â†’ Cron Expression anpassen
- Beispiele:
  - `0 8 * * *` = TÃ¤glich 8:00
  - `0 18 * * *` = TÃ¤glich 18:00
  - `0 8 * * 1-5` = Werktags 8:00

### OpenAI Modell Ã¤ndern

Im Workflow **"02 - Article Summarization"**:
- Ã–ffne den **"OpenAI Summarize"** Node
- Model: `gpt-4o-mini` (gÃ¼nstig, schnell) oder `gpt-4o` (bessere QualitÃ¤t, teurer)
- Temperature: `0.3` (konsistenter) bis `0.7` (kreativer)

## ğŸ›‘ Container stoppen/neustarten

```bash
# Stoppen
docker-compose down

# Neustarten
docker-compose up -d

# Neu bauen (bei Ã„nderungen)
docker-compose down
docker-compose up -d --build

# Alles lÃ¶schen (inkl. Daten!)
docker-compose down -v
```

## ğŸ› Troubleshooting

### Problem: "Cannot connect to PostgreSQL"
```bash
# PrÃ¼fe ob Container lÃ¤uft
docker-compose ps

# PrÃ¼fe Logs
docker-compose logs postgres

# Neustart
docker-compose restart postgres
```

### Problem: "OpenAI API Error"
- PrÃ¼fe ob API Key korrekt ist
- PrÃ¼fe OpenAI Account Balance: https://platform.openai.com/usage
- Teste mit curl:
```bash
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

### Problem: "Email wird nicht gesendet"
- PrÃ¼fe SMTP Credentials in n8n
- FÃ¼r Gmail: Verwende **App-Passwort**, nicht normales Passwort
- Teste SMTP manuell:
```bash
docker exec -it news-agent-n8n sh
# Im Container:
telnet smtp.gmail.com 587
```

### Problem: "Workflows werden nicht automatisch ausgefÃ¼hrt"
- PrÃ¼fe ob Workflows **aktiviert** sind (Toggle oben rechts)
- Schedule Trigger muss grÃ¼n sein
- PrÃ¼fe n8n Logs: `docker-compose logs n8n`

### Problem: "Zu viele Duplikate"
Die Deduplizierung basiert auf der **URL**. Wenn verschiedene Feeds leicht unterschiedliche URLs haben (z.B. mit Tracking-Parametern), werden sie als unterschiedlich erkannt.

**LÃ¶sung:** Erweitere die Deduplizierungs-Logik im Workflow 01.

## ğŸ“ˆ NÃ¤chste Schritte (Phase 2)

- [ ] Keyword-Filtering hinzufÃ¼gen
- [ ] Mehrere Output-KanÃ¤le (Slack, Teams)
- [ ] Web-Dashboard fÃ¼r Artikel-Verwaltung
- [ ] Sentiment-Analyse
- [ ] Updater-Funktion (Quellen per Chat hinzufÃ¼gen)
- [ ] Redis fÃ¼r Caching und Rate Limiting

## ğŸ“ Lizenz

Dieses Projekt ist ein MVP fÃ¼r persÃ¶nliche/interne Nutzung.

---

**Viel Erfolg! ğŸš€**

Bei Fragen: PrÃ¼fe die Logs und die [n8n Dokumentation](https://docs.n8n.io/).
